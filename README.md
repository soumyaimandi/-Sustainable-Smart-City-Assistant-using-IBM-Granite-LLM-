

# ğŸŒ† Sustainable Smart City Assistant using IBM Granite LLM

## ğŸ“˜ Overview

The **Sustainable Smart City Assistant** is an AI-powered application designed to support smart city development and sustainability initiatives using **IBMâ€™s Granite Large Language Model (LLM)**. This assistant can answer urban planning questions, suggest eco-friendly solutions, analyze environmental issues, and provide intelligent insightsâ€”all through natural language interaction.

It is built using **IBM Granite LLM via Hugging Face**, with development done in **Google Colab** and **Jupyter Notebook**, and packaged as an executable script in `app.py` for easy reuse and deployment.

---

## ğŸ” Features

* ğŸŒ± Recommends sustainable urban solutions
* ğŸ™ï¸ Offers insights for smart city infrastructure
* ğŸŒ Answers environmental and policy-related questions
* ğŸ¤– Powered by IBM Granite LLM via Hugging Face
* ğŸ–¥ï¸ Run locally via `app.py` or explore in Jupyter Notebook/Colab

---

## ğŸ§  Technologies Used

* **IBM Granite LLM** (via Hugging Face API)
* **Python 3.8+**
* **Google Colab** & **Jupyter Notebook** (for development/testing)
* **Hugging Face Transformers**
* **Command-line execution with `app.py`**

---

## ğŸš€ Getting Started

### âœ… Prerequisites

1. Python 3.8 or higher
2. Hugging Face account & API key
3. Git (optional, for cloning)
4. Internet connection (required to access the LLM)

---

### ğŸ’» Run the Project Locally

1. **Clone the Repository**

   ```bash
   git clone https://github.com/your-username/smart-city-assistant.git
   cd smart-city-assistant
   ```

2. **Install Required Dependencies**

   ```bash
   pip install transformers huggingface_hub
   ```

3. **Set Hugging Face API Token**
   You can log in from within the script or set an environment variable:

   ```bash
   export HUGGINGFACEHUB_API_TOKEN=your_huggingface_api_key
   ```

4. **Run the Application**

   ```bash
   python app.py
   ```

---

### ğŸŒ Option: Run in Google Colab

1. Open the notebook in Colab using the badge below:

   [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](your-colab-notebook-link-here)

2. Insert your Hugging Face API key when prompted in the notebook.

3. Run all cells step-by-step.

---

## ğŸ“¦ Project Structure

```
smart-city-assistant/
â”‚
â”œâ”€â”€ app.py                         # Main executable script
â”œâ”€â”€ smart_city_assistant.ipynb     # Development/demo notebook
â”œâ”€â”€ README.md                      # Project documentation
â””â”€â”€ assets/                        # Optional assets (e.g., images)
```

---

## ğŸ“Œ How It Works

1. Accepts a user query related to smart city sustainability.
2. Sends the query to IBM Granite LLM via Hugging Face API.
3. Displays intelligent, actionable insights as a response.

---

## ğŸ’¡ Example Use Cases

* â€œHow can smart traffic systems reduce carbon emissions?â€
* â€œWhat are the best practices for waste management in urban areas?â€
* â€œSuggest sustainable architecture models for city planning.â€

---

## ğŸ¤ Contribution

Pull requests and feedback are welcome! If you'd like to contribute:

1. Fork the repo
2. Create a new branch
3. Submit a PR with your improvements

---

## ğŸ“„ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

---

## ğŸ§© Acknowledgments

* IBM for Granite LLM
* Hugging Face for model API access
* Google Colab for development and testing support

---



